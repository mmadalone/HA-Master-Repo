blueprint:
  domain: automation
  name: Music Assistant - Local LLM Enhanced Voice Support Blueprint
  author: Music Assistant Project (style-guide fixes by madalone)
  source_url: https://github.com/music-assistant/voice-support/blob/main/llm-enhanced-local-assist-blueprint/mass_llm_enhanced_assist_blueprint_en.yaml
  description: '![Image](https://github.com/music-assistant/voice-support/blob/main/assets/music-assistant.png?raw=true)

    # Play media using voice commands with LLM assistance

    Uses an LLM conversation agent to parse voice commands into structured
    media queries, then plays them via Music Assistant. Supports area-based
    and player-based targeting with automatic fallback to default player.

    ### Recent changes

    - **v2:** Added error handling on LLM JSON parsing, template safety,
    radio_mode choose blocks, numbered comments, parallel mode limits

    - **v1:** Original upstream version (20250404)


    ### Blueprint setup

    #### Required

    * Select an LLM conversation agent to be used with the automation. The blueprint
    is intended to be used with an LLM conversation agent without control of the house.

    #### Optional

    * Set a `Default Player` to be used when no target is mentioned in the request
    and the request doesn''t come from an area with a Music Assistant player.

    * Change the setting for `Radio Mode`. By default this is set to use the `Don''t
    stop the music` setting on the Music Assistant player.

    * Change the trigger sentence or add more, you can also use this to translate
    the sentence to your own language.

    * Change the responses or translate them to your own language.

    * Change the setting to expose area names and player names to the LLM, the default
    setting is to send them. In case you change the settings in the blueprint and
    do not expose the area names and player names to the LLM, the name must exactly
    match the name of the area or player in Home Assistant.

    * Change the prompt which is used to have the LLM provide the correct data. You
    don''t need to translate this if you use a different language.


    ### Usage

    All sentences must:

    * start with the words `Shuffle`, `Play` or `Listen to` followed by a query about
    what you want to play. If you start with `Shuffle`, the player will have shuffle
    enabled.

    * then be optionally followed by one or more area names and/or one or more device
    names to play the music on.


    ### How the target for the media is determined:

    1. If one or more areas and/or Music Assistant players are mentioned in the request,
    those are used.

    2. If no target was mentioned, the automation checks if the request came from a
    device in an area with a Music Assistant player.

    3. If neither works, the `Default Player` is used. If no default is set, an error
    response is returned.


    #### Examples

    ```

    Play the best songs from Pink Floyd in the kitchen

    Listen to the album Greatest Hits by James Taylor in the kitchen

    Play track New Years Day in the bedroom

    Listen to the playlist Classic Rock in the study

    Listen to BBC Radio 1 in the bedroom

    Play songs by U2

    Play music by the composer from oppenheimer

    Shuffle songs by Muse

    ```'
  homeassistant:
    min_version: 2024.10.0
  input:
    stage_1_core:
      name: "Stage 1 — Core settings"
      icon: mdi:cog
      description: LLM agent and default playback target.
      input:
        llm_agent:
          name: LLM conversation agent
          description: >
            The LLM agent used to parse voice commands into structured media queries.
            Should be configured WITHOUT house control — it only needs to return JSON.
          selector:
            entity:
              filter:
                - domain:
                    - conversation
              multiple: false

        default_player:
          name: Default Player
          description: >
            Fallback Music Assistant player used when no target area or player
            can be determined from the voice command or device location.
            Leave empty to return an error response instead.
          selector:
            entity:
              filter:
                - integration: music_assistant
                  domain:
                    - media_player
              multiple: false
          default:

    stage_2_playback:
      name: "Stage 2 — Playback settings"
      icon: mdi:music
      description: Controls how Music Assistant handles the playback request.
      input:
        play_continuously:
          name: Radio Mode
          description: >
            Controls the "radio_mode" setting for play_media.
            "Use player settings" defers to the player's "Don't stop the music" setting.
            "Always" continuously adds new songs. "Never" stops after the queue ends.
          selector:
            select:
              options:
                - label: "Use player settings"
                  value: "Use player settings"
                - label: "Always — keep adding songs"
                  value: "Always"
                - label: "Never — stop when queue ends"
                  value: "Never"
              multiple: false
              custom_value: false
              sort: false
          default: "Use player settings"

    stage_3_responses:
      name: "Stage 3 — Trigger & response settings"
      icon: mdi:chat
      description: >
        Voice trigger sentences and response templates. Translate these to
        use the blueprint in another language. <media_info>, <area_info>,
        and <player_info> are replaced dynamically.
      collapsed: true
      input:
        trigger:
          name: Conversation trigger sentences
          description: >
            Trigger patterns for voice commands. Text in [ ] is optional,
            ( | ) provides alternatives, {query} captures the media request.
          selector:
            text:
              multiline: false
              multiple: true
          default:
            - (shuffle|play|listen to) {query}

        combine_text:
          name: Combine word
          description: >
            Word used to join multiple targets in the response
            (e.g., "living room AND kitchen").
          selector:
            text:
              multiline: false
              multiple: false
          default: and

        no_target_response:
          name: No target response
          description: Returned when no target could be determined and no default player is set.
          selector:
            text:
              multiline: false
              multiple: false
          default: No target could be determined and no default player is set

        area_response:
          name: Area response
          description: Returned when only area targets are used.
          selector:
            text:
              multiline: false
              multiple: false
          default: >-
            Now {{ 'shuffling' if 'shuffle' in trigger.sentence | lower else 'playing'}}
            <media_info> in <area_info>

        player_response:
          name: Player response
          description: Returned when only specific player targets are used.
          selector:
            text:
              multiline: false
              multiple: false
          default: >-
            Now {{ 'shuffling' if 'shuffle' in trigger.sentence | lower else 'playing'}}
            <media_info> on <player_info>

        area_and_player_response:
          name: Area and Player response
          description: Returned when both area and player targets are used.
          selector:
            text:
              multiline: false
              multiple: false
          default: >-
            Now {{ 'shuffling' if 'shuffle' in trigger.sentence | lower else 'playing'}}
            <media_info> in <area_info> and on <player_info>

    stage_4_prompt:
      name: "Stage 4 — LLM prompt tuning"
      icon: mdi:robot
      description: >
        Fine-tune the LLM prompt for your specific model. The default works
        for most LLMs. Only modify if you know what you're doing.
      collapsed: true
      input:
        expose_players:
          name: Expose Music Assistant Players
          description: >
            When enabled, sends player names to the LLM for fuzzy matching.
            When disabled, voice commands must use exact player names.
          selector:
            boolean: {}
          default: true

        expose_areas:
          name: Expose areas with Music Assistant Players
          description: >
            When enabled, sends area names to the LLM for fuzzy matching.
            When disabled, voice commands must use exact area names.
          selector:
            boolean: {}
          default: true

        llm_prompt_intro:
          name: Introduction for LLM prompt
          description: Sets the LLM's role and expected JSON output structure.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            You are an AI process that transforms a music search query into
            a structured JSON. For every query, you must research and provide specific
            details—such as titles, artist names, or album names—if they are not directly
            mentioned in the query. For example, if the query is "play the latest
            album by Foo Fighters," you should research the latest album title and
            include it in the JSON response. If the query specifies only an artist,
            album, or playlist, provide details as appropriate without assuming unspecified
            specifics.

            This is the voice command query provided by the user: "{{ trigger.sentence }}"

            Here is the structured JSON that I expect in response {"action_data":
            {"media_id":"name", "media_type":"type", "artist":"name", "album":"name"},
            "media_description": "description of media", "target_data": {"areas":
            ["area name"], "players": ["player name"]}}

        llm_prompt_media_type:
          name: Media type LLM prompt
          description: Explains the media_type parameter constraints to the LLM.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            The argument "media_type" is mandatory and must always be provided
            no matter what!

            "media_type" can only be one of 5 different values:

            - "track" if the search is about a specific track or a list of tracks.

            - "album" if the search is about an album or a list of albums.

            - "artist" if the search is about an artist.

            - "playlist" if the search specifically requests a playlist.

            - "radio" in case the search is a radio channel.

            media_type is mandatory and must always be provided. In case a request
            does not match any of these types, for example when music from a specific
            genre is requested, then use "track" and provide a list of matching songs
            for the "media_id" parameter.

        llm_prompt_media_id:
          name: Media ID LLM prompt
          description: Explains the media_id parameter and multi-track formatting.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            The argument "media_id" is also mandatory and must always be provided
            no matter what!

            media_id is the most specific from track, album, and artist.

            "track" and "artist" can be a single value or multiple values.

            - If the search is about a track: Then media_id is the track name or a
            json formatted list of track names. In case there are multiple artists
            in the result, use both the artist name and song name separated by a dash
            as track name (example: "Artist name - Song name"). In case all songs
            are from the same artist, use the artist for the "artist" parameter, and
            only use the song names as track name.

            - If the search is about an album: Then media_id is the album name or
            a json formatted list of album names.

            - If the search is about an artist: Then media_id is the artist name.

            - If the search is a specific playlist: Then media_id is the requested
            playlist.

            - If the search is a radio channel: Then media_id is the requested channel.

            "media_id" is a mandatory argument and must always be provided.

        llm_prompt_artist_album:
          name: Artist and album LLM prompt
          description: Explains optional artist/album fields for search refinement.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            In case it is needed, the fields "artist" and "album" can be used
            to further restrict the search.

            For example, if the input is "Hells Bells by ACDC", then the output should
            be {"action_data":{"media_id":"Hells Bells", "media_type":"track", "artist":"AC/DC"}}

            "artist" and "album" are optional and never used in the case of a playlist
            search.

        llm_prompt_examples:
          name: Examples action data LLM prompt
          description: Concrete JSON examples for common query types.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            There can be several types of answers for the "action_data" dictionary.
            Here are some examples:

            Just an artist >> {"action_data":{"media_id": "artist name", "media_type":"artist"}}.

            An album by an artist >> {"action_data":{"media_id": "album name", "media_type":
            "album", "artist": "artist name"}}.

            A track by an artist >> {"action_data":{"media_id": "track name", "media_type":
            "track", "artist": "artist name"}}.

            Just a track if the artist is not known >> {"action_data":{"media_id":
            "track name", "media_type": "track"}}.

            Just a playlist if the request is a specific playlist >> {"action_data":{"media_id":"playlist
            name", "media_type":"playlist"}}.

            Multiple tracks of different artists >> {"action_data":{"media_id": ["Artist
            name - Song name", "Another artist name - Another song name", "Another
            artist name - Another song name"], "media_type":"track"}}.

            Multiple tracks of the same artist >> {"action_data":{"media_id": ["Song
            name", "Another song name"], "artist": "artist name", "media_type":"track"}}


        llm_prompt_media_description:
          name: Media description LLM prompt
          description: Explains the media_description key used for voice responses.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            The "media_description" key is used to describe the media which
            will be played. This can be taken from the voice command query, but it
            should be only the part which is relevant for the media. So if the voice
            request is "Play the best Queen songs on the living room player" the value
            for "media_description" should be "the best Queen songs"

        llm_prompt_target:
          name: Target data LLM prompt
          description: Explains target_data for area/player routing.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            The "target_data" key is used to define the information on which
            the request should be played.

            {% if expose_areas %}These are the area names which have a Music Assistant
            player: {{ area_names }}. Only use these area names for the "target_data".
            In case another area description is used in the request, try to map it
            to one of these area names." {% endif %}

            In case the query requests the music to be played in one or more areas
            {% if expose_areas %}in which a Music Assistant player is located{% endif
            %}, use {"areas": ["area name"]} for "target_data". Always use a list
            with area names, even when there is only one. {% if expose_areas %}Try
            to match the areas mentioned in the request to the provided area names.
            Only use area names from the list provided. {% else %}Do not include articles
            like "the" at the start of the area name. So if the request is "Play music
            from Queen in the kitchen" use "kitchen" as area name. Besides removing
            the first article, use exactly what was provided in the request.{% endif
            %}When no area is mentioned in the voice request{% if expose_areas %}
            or no area could be matched{% endif %}, use {"areas":[]}

            {% if expose_players %}These are the Music Assistant players in the system:
            {{ player_names }}. Only use these names for the "target_data". In case
            another player name is mentioned in the request, try to map it to one
            of these player names.{% endif %}

            In case the query requests the music to be played on one or more media
            players, use {"players": ["player name"]} for "target_data". Always use
            a list with player names, even when there is only one. {% if expose_players
            %}Try to match the players mentioned in the request to the provided player
            names. Only use player names from the list provided. {% else %}Do not
            include articles like "the" at the start of the player name. So if the
            request is "Play music from Queen on the bedroom Sonos" use "bedroom Sonos"
            as area name. Besides removing the first article, use exactly what was
            provided in the request.{% endif %}When no player is mentioned in the
            voice request{% if expose_players %} or no player could be matched {%
            endif %}, use {"players":[]}

        llm_prompt_outro:
          name: Outro for LLM prompt
          description: Final instructions ensuring raw JSON output.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            Note that the input query can be in a different language. For
            the "media_type" the untranslated English terms should be used, in case
            of a playlist search use the language used in the input.

            IMPORTANT: You must reply with only the JSON model, nothing before nor
            after because your response will be processed by a search component of
            a media player service. So also no code tags. Only the JSON!

        llm_prompt:
          name: Legacy LLM prompt setting
          description: >
            This field held the LLM prompt before it was split into parts.
            It is no longer used by the automation — kept only for reference
            so you can copy old customizations into the fields above.
          selector:
            text:
              multiline: true
              multiple: false
          default: ""

triggers:
  # 1 — Voice trigger: captures "shuffle/play/listen to {query}" from Assist
  - alias: Trigger on voice music request
    trigger: conversation
    command: !input trigger

actions:
  # ── Stage 1 — Collect inputs & build prompt ──────────────────────────

  # 2 — Resolve blueprint inputs into working variables.
  #     area_names and player_names are built from the MA integration
  #     so the LLM can fuzzy-match spoken names to real entities.
  - alias: "2 · Collect inputs and build prompt variables"
    variables:
      version: 20260208
      shuffle: "{{ 'shuffle' in trigger.sentence | lower }}"
      expose_areas: !input expose_areas
      expose_players: !input expose_players
      prompt:
        intro: !input llm_prompt_intro
        media_type: !input llm_prompt_media_type
        media_id: !input llm_prompt_media_id
        artist_album: !input llm_prompt_artist_album
        examples: !input llm_prompt_examples
        description: !input llm_prompt_media_description
        target: !input llm_prompt_target
        outro: !input llm_prompt_outro
      area_names: >-
        {{ integration_entities('music_assistant')
           | map('area_name')
           | reject('none')
           | join(', ') }}
      player_names: >-
        {{ integration_entities('music_assistant')
           | map('state_attr', 'friendly_name')
           | reject('none')
           | join(', ') }}

  # ── Stage 2 — LLM query ─────────────────────────────────────────────

  # 3 — Send the assembled prompt to the conversation agent.
  #     The LLM should return raw JSON (no markdown, no code fences).
  - alias: "3 · Send prompt to LLM conversation agent"
    action: conversation.process
    data:
      text: "{{ prompt.values() | join('\n\n') }}"
      agent_id: !input llm_agent
    response_variable: result

  # 4 — Parse the LLM response. This is the critical failure point:
  #     LLMs can return markdown-wrapped JSON, apologies, or garbage.
  #     We strip code fences, attempt from_json, and fall back to an
  #     empty dict so downstream steps never crash on missing keys.
  - alias: "4 · Parse LLM JSON with error handling"
    variables:
      llm_raw: >-
        {{ result.response.speech.plain.speech | default('{}', true) }}
      llm_cleaned: >-
        {% set raw = llm_raw | trim %}
        {% if raw.startswith('```') %}
          {% set raw = raw | regex_replace('^```[a-zA-Z]*\n?', '') | regex_replace('\n?```$', '') | trim %}
        {% endif %}
        {{ raw }}
      llm_result: >-
        {{ llm_cleaned | from_json | default({}, true) }}
      llm_parse_ok: >-
        {{ llm_result is mapping
           and llm_result.get('action_data', {}).get('media_id', '') | length > 0
           and llm_result.get('action_data', {}).get('media_type', '') | length > 0 }}

  # 5 — Gate: bail early if the LLM returned unparseable garbage.
  #     Gives the user a clear error instead of a silent crash.
  - alias: "5 · Bail if LLM response could not be parsed"
    if:
      - alias: "Check llm_parse_ok flag"
        condition: template
        value_template: "{{ not llm_parse_ok }}"
    then:
      - alias: "5a · Return parse-error response to voice assistant"
        set_conversation_response: >-
          Sorry, I couldn't understand the music request. Please try again.
      - stop: "LLM returned unparseable response"

  # ── Stage 3 — Resolve targets ───────────────────────────────────────

  # 6 — Build target entity_ids and area_ids from LLM output.
  #     Falls back to device area, then default player, then empty.
  - alias: "6 · Resolve playback targets"
    variables:
      play_continuously: !input play_continuously
      llm_action_data_media_id: >-
        {{ llm_result.get('action_data', {}).get('media_id', '') }}
      llm_action_data_media_type: >-
        {{ llm_result.get('action_data', {}).get('media_type', 'track') }}
      llm_action_data_artist: >-
        {{ llm_result.get('action_data', {}).get('artist', '') }}
      llm_action_data_album: >-
        {{ llm_result.get('action_data', {}).get('album', '') }}
      llm_target_data:
        entity_id: >-
          {% set players = llm_result.get('target_data', {}).get('players', []) %}
          {% set players = players | join('|') if players is list else players %}
          {{ integration_entities('music_assistant')
             | expand
             | selectattr('name', 'in',
                 player_names.split(', ')
                 | select('search', players, ignorecase=true)
                 | list)
             | map(attribute='entity_id')
             | list if players else [] }}
        area_id: >-
          {% set areas = llm_result.get('target_data', {}).get('areas', []) %}
          {% set areas = areas | join('|') if areas is list else areas %}
          {{ area_names.split(', ')
             | select('search', areas, ignorecase=true)
             | map('area_id')
             | list if areas else [] }}
      llm_target: >-
        {{ (llm_result.get('target_data', {}).get('players', []) | length > 0)
           or (llm_result.get('target_data', {}).get('areas', []) | length > 0) }}
      device_area: >-
        {{ area_id(trigger.device_id) | default('', true)
           if area_name(trigger.device_id) | default('', true) in area_names.split(', ')
           else '' }}
      default_player: !input default_player
      backup_target: >-
        {{ (dict(area_id=[device_area]) if device_area)
           or (dict(entity_id=[default_player]) if default_player)
           or {} }}
      target_data: >-
        {{ (llm_target_data if llm_target else backup_target) | default({}, true) }}
      target: >-
        {{ dict(target_data.items() | selectattr('1')) }}

  # ── Stage 4 — Playback ────────────────────────────────────────────────

  # 7 — Gate: only attempt playback if we resolved at least one target.
  - alias: "7 · Play music only if target was resolved"
    if:
      - alias: "Check target is non-empty"
        condition: template
        value_template: "{{ target | length > 0 }}"
    then:
      # 8 — Build play_media data dict via choose block.
      #     Uses explicit branches instead of a templated dict with 'NA'
      #     sentinel values, per §7.2 anti-pattern guidance.
      - alias: "8 · Call play_media with radio_mode via choose"
        choose:
          # 8a — Radio mode: Never (explicit false)
          - alias: "8a · Radio mode Never"
            conditions:
              - condition: template
                value_template: "{{ play_continuously == 'Never' }}"
            sequence:
              - alias: "8a · play_media with radio_mode false"
                action: music_assistant.play_media
                data:
                  media_id: "{{ llm_action_data_media_id }}"
                  media_type: "{{ llm_action_data_media_type }}"
                  artist: "{{ llm_action_data_artist if llm_action_data_artist else none }}"
                  album: "{{ llm_action_data_album if llm_action_data_album else none }}"
                  radio_mode: false
                target: "{{ target }}"

          # 8b — Radio mode: Always (true, unless media_type is already radio)
          - alias: "8b · Radio mode Always"
            conditions:
              - condition: template
                value_template: "{{ play_continuously == 'Always' }}"
            sequence:
              - alias: "8b · play_media with radio_mode true (unless radio type)"
                action: music_assistant.play_media
                data:
                  media_id: "{{ llm_action_data_media_id }}"
                  media_type: "{{ llm_action_data_media_type }}"
                  artist: "{{ llm_action_data_artist if llm_action_data_artist else none }}"
                  album: "{{ llm_action_data_album if llm_action_data_album else none }}"
                  radio_mode: "{{ llm_action_data_media_type != 'radio' }}"
                target: "{{ target }}"

        # 8c — Default: Use player settings (omit radio_mode entirely)
        default:
          - alias: "8c · play_media without radio_mode (use player setting)"
            action: music_assistant.play_media
            data:
              media_id: "{{ llm_action_data_media_id }}"
              media_type: "{{ llm_action_data_media_type }}"
              artist: "{{ llm_action_data_artist if llm_action_data_artist else none }}"
              album: "{{ llm_action_data_album if llm_action_data_album else none }}"
            target: "{{ target }}"

      # 9 — Set shuffle on/off based on trigger word.
      #     continue_on_error because shuffle failure shouldn't kill the whole run.
      - alias: "9 · Set shuffle mode on target player(s)"
        action: media_player.shuffle_set
        data:
          shuffle: "{{ shuffle }}"
        target: "{{ target }}"
        continue_on_error: true

  # ── Stage 5 — Build and return voice response ────────────────────────

  # 10 — Assemble the response template variables.
  #      Joins multiple areas/players with the configured combine word.
  - alias: "10 · Build response variables"
    variables:
      combine: !input combine_text
      responses:
        no_target: !input no_target_response
        only_area: !input area_response
        only_player: !input player_response
        area_player: !input area_and_player_response
      response: >-
        {% if target.get('area_id') and target.get('entity_id') %}
          area_player
        {% elif target.get('area_id') %}
          only_area
        {% elif target.get('entity_id') %}
          only_player
        {% else %}
          no_target
        {% endif %}
      area_list: >-
        {{ target.get('area_id', []) | map('area_name') | reject('none') | list }}
      area_info: >-
        {{ area_list[:-1] | join(', ') ~ ' ' ~ combine ~ ' ' ~ area_list[-1]
           if area_list | count > 2
           else area_list | join(' ' ~ combine ~ ' ') }}
      player_list: >-
        {{ target.get('entity_id', [])
           | map('state_attr', 'friendly_name')
           | reject('none')
           | list }}
      player_info: >-
        {{ player_list[:-1] | join(', ') ~ ' ' ~ combine ~ ' ' ~ player_list[-1]
           if player_list | count > 2
           else player_list | join(' ' ~ combine ~ ' ') }}
      media_info: >-
        {{ llm_result.get('media_description', '')
           | default(llm_action_data_media_id, true) }}

  # 11 — Return the final voice response to Assist.
  - alias: "11 · Set conversation response"
    set_conversation_response: >-
      {{ responses[response | trim]
         | replace('<media_info>', media_info)
         | replace('<area_info>', area_info)
         | replace('<player_info>', player_info) }}

mode: parallel
max: 10
max_exceeded: silent