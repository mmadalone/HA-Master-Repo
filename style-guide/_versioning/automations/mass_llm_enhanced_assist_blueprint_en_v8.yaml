blueprint:
  domain: automation
  name: Music Assistant – Local LLM Enhanced Voice Support
  author: Music Assistant Project (style-guide fixes by madalone)
  # source_url removed — no public fork yet. Upstream ref:
  # https://github.com/music-assistant/voice-support/blob/main/llm-enhanced-local-assist-blueprint/mass_llm_enhanced_assist_blueprint_en.yaml
  description: '![Image](https://github.com/music-assistant/voice-support/blob/main/assets/music-assistant.png?raw=true)

    # Play media using voice commands with LLM assistance

    Uses an LLM conversation agent to parse voice commands into structured
    media queries, then plays them via Music Assistant. Supports area-based
    and player-based targeting with automatic fallback to default player.

    ### Recent changes

    - **v8:** Removed source_url (no public fork), removed empty condition
    block, exposed playback verification delay as input, cleaned up
    development comments for stable release

    - **v7:** Fixed critical from_json parse failure — whitespace injection
    from non-trimmed Jinja tags in llm_cleaned, plus from_json exception
    guard (default() only catches undefined, not ValueError)

    - **v6:** Documented conversation.process timeout gap, added post-playback
    state verification, en-dash in name, improved shuffle alias

    - **v5:** Condition block before variables, actions→action singular,
    continue_on_error moved to individual play_media branches, null-safe
    prompt join, choose-block response routing

    - **v3:** Fixed empty-list crash, added enqueue_mode, removed none
    coercion, top-level variables, template safety, removed dead input


    ### Blueprint setup

    #### Required

    * Select an LLM conversation agent to be used with the automation. The blueprint
    is intended to be used with an LLM conversation agent without control of the house.

    #### Optional

    * Set a `Default Player` to be used when no target is mentioned in the request
    and the request doesn''t come from an area with a Music Assistant player.

    * Change the setting for `Radio Mode`. By default this is set to use the `Don''t
    stop the music` setting on the Music Assistant player.

    * Change the trigger sentence or add more, you can also use this to translate
    the sentence to your own language.

    * Change the responses or translate them to your own language.

    * Change the setting to expose area names and player names to the LLM, the default
    setting is to send them. In case you change the settings in the blueprint and
    do not expose the area names and player names to the LLM, the name must exactly
    match the name of the area or player in Home Assistant.

    * Change the prompt which is used to have the LLM provide the correct data. You
    don''t need to translate this if you use a different language.


    ### Usage

    All sentences must:

    * start with the words `Shuffle`, `Play` or `Listen to` followed by a query about
    what you want to play. If you start with `Shuffle`, the player will have shuffle
    enabled.

    * then be optionally followed by one or more area names and/or one or more device
    names to play the music on.


    ### How the target for the media is determined:

    1. If one or more areas and/or Music Assistant players are mentioned in the request,
    those are used.

    2. If no target was mentioned, the automation checks if the request came from a
    device in an area with a Music Assistant player.

    3. If neither works, the `Default Player` is used. If no default is set, an error
    response is returned.


    #### Examples

    ```

    Play the best songs from Pink Floyd in the kitchen

    Listen to the album Greatest Hits by James Taylor in the kitchen

    Play track New Years Day in the bedroom

    Listen to the playlist Classic Rock in the study

    Listen to BBC Radio 1 in the bedroom

    Play songs by U2

    Play music by the composer from oppenheimer

    Shuffle songs by Muse

    ```'
  homeassistant:
    min_version: 2024.10.0
  input:
    stage_1_core:
      name: "Stage 1 — Core settings"
      icon: mdi:cog
      description: LLM agent and default playback target.
      collapsed: false
      input:
        llm_agent:
          name: LLM conversation agent
          description: >
            The LLM agent used to parse voice commands into structured media queries.
            Should be configured WITHOUT house control — it only needs to return JSON.
          selector:
            entity:
              filter:
                - domain:
                    - conversation
              multiple: false

        default_player:
          name: Default Player
          description: >
            Fallback Music Assistant player used when no target area or player
            can be determined from the voice command or device location.
            Leave empty to return an error response instead.
          selector:
            entity:
              filter:
                - integration: music_assistant
                  domain:
                    - media_player
              multiple: false
          default:

    stage_2_playback:
      name: "Stage 2 — Playback settings"
      icon: mdi:music
      description: Controls how Music Assistant handles the playback request.
      collapsed: false
      input:
        play_continuously:
          name: Radio Mode
          description: >
            Controls the "radio_mode" setting for play_media.
            "Use player settings" defers to the player's "Don't stop the music" setting.
            "Always" continuously adds new songs. "Never" stops after the queue ends.
          selector:
            select:
              options:
                - label: "Use player settings"
                  value: "Use player settings"
                - label: "Always — keep adding songs"
                  value: "Always"
                - label: "Never — stop when queue ends"
                  value: "Never"
              multiple: false
              custom_value: false
              sort: false
          default: "Use player settings"

        enqueue_mode:
          name: Enqueue Mode
          description: >
            Controls how new media is added to the player's queue.
            "Replace" clears the queue and plays immediately (default).
            "Add" appends to the end of the current queue.
            "Next" inserts after the currently playing track.
          selector:
            select:
              options:
                - label: "Replace — clear queue and play"
                  value: "replace"
                - label: "Add — append to queue"
                  value: "add"
                - label: "Next — play after current track"
                  value: "next"
              multiple: false
              custom_value: false
              sort: false
          default: "replace"

        playback_verify_delay:
          name: Playback verification delay (seconds)
          description: >
            How long to wait after play_media before checking if playback
            actually started. Increase if your MA backend is slow to start
            streams (e.g., remote providers, Bluetooth speakers).
          selector:
            number:
              min: 1
              max: 10
              step: 1
              unit_of_measurement: seconds
              mode: slider
          default: 2

    stage_3_responses:
      name: "Stage 3 — Trigger & response settings"
      icon: mdi:chat
      description: >
        Voice trigger sentences and response templates. Translate these to
        use the blueprint in another language. <media_info>, <area_info>,
        and <player_info> are replaced dynamically.
      collapsed: true
      input:
        trigger:
          name: Conversation trigger sentences
          description: >
            Trigger patterns for voice commands. Text in [ ] is optional,
            ( | ) provides alternatives, {query} captures the media request.
          selector:
            text:
              multiline: false
              multiple: true
          default:
            - (shuffle|play|listen to) {query}

        combine_text:
          name: Combine word
          description: >
            Word used to join multiple targets in the response
            (e.g., "living room AND kitchen").
          selector:
            text:
              multiline: false
              multiple: false
          default: and

        no_target_response:
          name: No target response
          description: Returned when no target could be determined and no default player is set.
          selector:
            text:
              multiline: false
              multiple: false
          default: No target could be determined and no default player is set

        area_response:
          name: Area response
          description: >
            Returned when only area targets are used.
            Use <action_word> for "shuffling"/"playing", <media_info>, <area_info>.
          selector:
            text:
              multiline: false
              multiple: false
          default: >-
            Now <action_word> <media_info> in <area_info>

        player_response:
          name: Player response
          description: >
            Returned when only specific player targets are used.
            Use <action_word> for "shuffling"/"playing", <media_info>, <player_info>.
          selector:
            text:
              multiline: false
              multiple: false
          default: >-
            Now <action_word> <media_info> on <player_info>

        area_and_player_response:
          name: Area and Player response
          description: >
            Returned when both area and player targets are used.
            Use <action_word> for "shuffling"/"playing", <media_info>,
            <area_info>, <player_info>.
          selector:
            text:
              multiline: false
              multiple: false
          default: >-
            Now <action_word> <media_info> in <area_info> and on <player_info>

    stage_4_prompt:
      name: "Stage 4 — LLM prompt tuning"
      icon: mdi:robot
      description: >
        Fine-tune the LLM prompt for your specific model. The default works
        for most LLMs. Only modify if you know what you're doing.
      collapsed: true
      input:
        expose_players:
          name: Expose Music Assistant Players
          description: >
            When enabled, sends player names to the LLM for fuzzy matching.
            When disabled, voice commands must use exact player names.
          selector:
            boolean: {}
          default: true

        expose_areas:
          name: Expose areas with Music Assistant Players
          description: >
            When enabled, sends area names to the LLM for fuzzy matching.
            When disabled, voice commands must use exact area names.
          selector:
            boolean: {}
          default: true

        llm_prompt_intro:
          name: Introduction for LLM prompt
          description: Sets the LLM's role and expected JSON output structure.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            You are an AI process that transforms a music search query into
            a structured JSON. For every query, you must research and provide specific
            details—such as titles, artist names, or album names—if they are not directly
            mentioned in the query. For example, if the query is "play the latest
            album by Foo Fighters," you should research the latest album title and
            include it in the JSON response. If the query specifies only an artist,
            album, or playlist, provide details as appropriate without assuming unspecified
            specifics.

            This is the voice command query provided by the user: "{{ trigger.sentence }}"

            Here is the structured JSON that I expect in response {"action_data":
            {"media_id":"name", "media_type":"type", "artist":"name", "album":"name"},
            "media_description": "description of media", "target_data": {"areas":
            ["area name"], "players": ["player name"]}}

        llm_prompt_media_type:
          name: Media type LLM prompt
          description: Explains the media_type parameter constraints to the LLM.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            The argument "media_type" is mandatory and must always be provided
            no matter what!

            "media_type" can only be one of 5 different values:

            - "track" if the search is about a specific track or a list of tracks.

            - "album" if the search is about an album or a list of albums.

            - "artist" if the search is about an artist.

            - "playlist" if the search specifically requests a playlist.

            - "radio" in case the search is a radio channel.

            media_type is mandatory and must always be provided. In case a request
            does not match any of these types, for example when music from a specific
            genre is requested, then use "track" and provide a list of matching songs
            for the "media_id" parameter.

        llm_prompt_media_id:
          name: Media ID LLM prompt
          description: Explains the media_id parameter and multi-track formatting.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            The argument "media_id" is also mandatory and must always be provided
            no matter what!

            media_id is the most specific from track, album, and artist.

            "track" and "artist" can be a single value or multiple values.

            - If the search is about a track: Then media_id is the track name or a
            json formatted list of track names. In case there are multiple artists
            in the result, use both the artist name and song name separated by a dash
            as track name (example: "Artist name - Song name"). In case all songs
            are from the same artist, use the artist for the "artist" parameter, and
            only use the song names as track name.

            - If the search is about an album: Then media_id is the album name or
            a json formatted list of album names.

            - If the search is about an artist: Then media_id is the artist name.

            - If the search is a specific playlist: Then media_id is the requested
            playlist.

            - If the search is a radio channel: Then media_id is the requested channel.

            "media_id" is a mandatory argument and must always be provided.

        llm_prompt_artist_album:
          name: Artist and album LLM prompt
          description: Explains optional artist/album fields for search refinement.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            In case it is needed, the fields "artist" and "album" can be used
            to further restrict the search.

            For example, if the input is "Hells Bells by ACDC", then the output should
            be {"action_data":{"media_id":"Hells Bells", "media_type":"track", "artist":"AC/DC"}}

            "artist" and "album" are optional and never used in the case of a playlist
            search.

        llm_prompt_examples:
          name: Examples action data LLM prompt
          description: Concrete JSON examples for common query types.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            There can be several types of answers for the "action_data" dictionary.
            Here are some examples:

            Just an artist >> {"action_data":{"media_id": "artist name", "media_type":"artist"}}.

            An album by an artist >> {"action_data":{"media_id": "album name", "media_type":
            "album", "artist": "artist name"}}.

            A track by an artist >> {"action_data":{"media_id": "track name", "media_type":
            "track", "artist": "artist name"}}.

            Just a track if the artist is not known >> {"action_data":{"media_id":
            "track name", "media_type": "track"}}.

            Just a playlist if the request is a specific playlist >> {"action_data":{"media_id":"playlist
            name", "media_type":"playlist"}}.

            Multiple tracks of different artists >> {"action_data":{"media_id": ["Artist
            name - Song name", "Another artist name - Another song name", "Another
            artist name - Another song name"], "media_type":"track"}}.

            Multiple tracks of the same artist >> {"action_data":{"media_id": ["Song
            name", "Another song name"], "artist": "artist name", "media_type":"track"}}


        llm_prompt_media_description:
          name: Media description LLM prompt
          description: Explains the media_description key used for voice responses.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            The "media_description" key is used to describe the media which
            will be played. This can be taken from the voice command query, but it
            should be only the part which is relevant for the media. So if the voice
            request is "Play the best Queen songs on the living room player" the value
            for "media_description" should be "the best Queen songs"

        llm_prompt_target:
          name: Target data LLM prompt
          description: Explains target_data for area/player routing.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            The "target_data" key is used to define the information on which
            the request should be played.

            {% if expose_areas %}These are the area names which have a Music Assistant
            player: {{ area_names }}. Only use these area names for the "target_data".
            In case another area description is used in the request, try to map it
            to one of these area names." {% endif %}

            In case the query requests the music to be played in one or more areas
            {% if expose_areas %}in which a Music Assistant player is located{% endif
            %}, use {"areas": ["area name"]} for "target_data". Always use a list
            with area names, even when there is only one. {% if expose_areas %}Try
            to match the areas mentioned in the request to the provided area names.
            Only use area names from the list provided. {% else %}Do not include articles
            like "the" at the start of the area name. So if the request is "Play music
            from Queen in the kitchen" use "kitchen" as area name. Besides removing
            the first article, use exactly what was provided in the request.{% endif
            %}When no area is mentioned in the voice request{% if expose_areas %}
            or no area could be matched{% endif %}, use {"areas":[]}

            {% if expose_players %}These are the Music Assistant players in the system:
            {{ player_names }}. Only use these names for the "target_data". In case
            another player name is mentioned in the request, try to map it to one
            of these player names.{% endif %}

            In case the query requests the music to be played on one or more media
            players, use {"players": ["player name"]} for "target_data". Always use
            a list with player names, even when there is only one. {% if expose_players
            %}Try to match the players mentioned in the request to the provided player
            names. Only use player names from the list provided. {% else %}Do not
            include articles like "the" at the start of the player name. So if the
            request is "Play music from Queen on the bedroom Sonos" use "bedroom Sonos"
            as area name. Besides removing the first article, use exactly what was
            provided in the request.{% endif %}When no player is mentioned in the
            voice request{% if expose_players %} or no player could be matched {%
            endif %}, use {"players":[]}

        llm_prompt_outro:
          name: Outro for LLM prompt
          description: Final instructions ensuring raw JSON output.
          selector:
            text:
              multiline: true
              multiple: false
          default: >-
            Note that the input query can be in a different language. For
            the "media_type" the untranslated English terms should be used, in case
            of a playlist search use the language used in the input.

            IMPORTANT: You must reply with only the JSON model, nothing before nor
            after because your response will be processed by a search component of
            a media player service. So also no code tags. Only the JSON!

triggers:
  - alias: "1 · Voice music request trigger"
    trigger: conversation
    command: !input trigger

# Top-level variables — resolves !input values and trigger context.
# These depend only on inputs and trigger data, not on LLM results.
variables:
  shuffle: "{{ 'shuffle' in (trigger.sentence | default('') | lower) }}"
  expose_areas: !input expose_areas
  expose_players: !input expose_players
  enqueue_mode: !input enqueue_mode
  prompt:
    intro: !input llm_prompt_intro
    media_type: !input llm_prompt_media_type
    media_id: !input llm_prompt_media_id
    artist_album: !input llm_prompt_artist_album
    examples: !input llm_prompt_examples
    description: !input llm_prompt_media_description
    target: !input llm_prompt_target
    outro: !input llm_prompt_outro
  # Safe-split versions use ||| delimiter for internal matching —
  # area/player names may contain commas. Original comma-separated
  # versions are kept for LLM prompt readability.
  area_names: >-
    {{ integration_entities('music_assistant')
       | map('area_name')
       | reject('none')
       | join(', ') }}
  area_names_safe: >-
    {{ integration_entities('music_assistant')
       | map('area_name')
       | reject('none')
       | join('|||') }}
  player_names: >-
    {{ integration_entities('music_assistant')
       | map('state_attr', 'friendly_name')
       | reject('none')
       | join(', ') }}
  player_names_safe: >-
    {{ integration_entities('music_assistant')
       | map('state_attr', 'friendly_name')
       | reject('none')
       | join('|||') }}

action:
  # ── Stage 1 — LLM query ─────────────────────────────────────────────

  # 2 — Send the assembled prompt to the conversation agent.
  #     continue_on_error catches agent crashes. HA has no native timeout
  #     for service calls — if the LLM hangs, this step blocks its slot
  #     indefinitely. Defense: configure the agent integration's own
  #     request timeout (OpenAI timeout, Ollama keep_alive, etc.).
  #     That timeout fires → agent returns error → continue_on_error
  #     catches it → gate 2a bails with a user-facing message.
  - alias: "2 · Send prompt to LLM conversation agent"
    continue_on_error: true
    action: conversation.process
    data:
      text: "{{ prompt.values() | reject('none') | join('\n\n') }}"
      agent_id: !input llm_agent
    response_variable: result

  # 2a — Gate: bail if the LLM call itself failed (timeout, crash, etc.)
  - alias: "2a · Bail if LLM call failed"
    if:
      - alias: "Check if result exists and has expected structure"
        condition: template
        value_template: >-
          {{ result is not defined
             or result.response is not defined
             or result.response.speech is not defined }}
    then:
      - alias: "2a · Return LLM-error response to voice assistant"
        set_conversation_response: >-
          Sorry, the music assistant couldn't reach the AI agent. Please try again.
      - stop: "LLM conversation.process call failed or returned empty response"

  # 3 — Parse the LLM response. LLMs can return markdown-wrapped JSON,
  #     apologies, or garbage. We strip code fences, shape-check before
  #     from_json, and fall back to empty dict so downstream steps never
  #     crash. Note: from_json throws ValueError on bad input — the
  #     | default() filter only catches undefined, not exceptions.
  - alias: "3 · Parse LLM JSON with error handling"
    variables:
      llm_raw: >-
        {{ result.response.speech.plain.speech | default('{}', true) }}
      llm_cleaned: >-
        {%- set raw = llm_raw | trim -%}
        {%- if raw.startswith('```') -%}
          {%- set raw = raw | regex_replace('^```[a-zA-Z]*\n?', '') | regex_replace('\n?```$', '') | trim -%}
        {%- endif -%}
        {{ raw }}
      llm_result: >-
        {%- set cleaned = llm_cleaned | trim -%}
        {%- if cleaned.startswith('{') and cleaned.endswith('}') -%}
          {{ cleaned | from_json }}
        {%- else -%}
          {{ {} }}
        {%- endif -%}
      llm_parse_ok: >-
        {{ llm_result is mapping
           and llm_result.get('action_data', {}).get('media_id', '') | length > 0
           and llm_result.get('action_data', {}).get('media_type', '') | length > 0 }}

  # 4 — Gate: bail early if the LLM returned unparseable garbage.
  #     Gives the user a clear error instead of a silent crash.
  - alias: "4 · Bail if LLM response could not be parsed"
    if:
      - alias: "Check llm_parse_ok flag"
        condition: template
        value_template: "{{ not llm_parse_ok }}"
    then:
      - alias: "4a · Return parse-error response to voice assistant"
        set_conversation_response: >-
          Sorry, I couldn't understand the music request. Please try again.
      - stop: "LLM returned unparseable response"

  # ── Stage 2 — Resolve targets ───────────────────────────────────────

  # 5 — Build target entity_ids and area_ids from LLM output.
  #     Falls back to device area → default player → empty.
  #     Named intermediates are visible in HA traces for debugging.
  #     trigger.device_id can be None for API/text pipeline calls.
  #     Uses _safe (|||) delimiter to handle names containing commas.
  - alias: "5 · Resolve playback targets"
    variables:
      play_continuously: !input play_continuously
      llm_action_data_media_id: >-
        {{ llm_result.get('action_data', {}).get('media_id', '') }}
      llm_action_data_media_type: >-
        {{ llm_result.get('action_data', {}).get('media_type', 'track') }}
      llm_action_data_artist: >-
        {{ llm_result.get('action_data', {}).get('artist', '') }}
      llm_action_data_album: >-
        {{ llm_result.get('action_data', {}).get('album', '') }}

      # 5a — Extract raw LLM target lists
      llm_requested_players: >-
        {{ llm_result.get('target_data', {}).get('players', []) }}
      llm_requested_areas: >-
        {{ llm_result.get('target_data', {}).get('areas', []) }}

      # 5b — Resolve player names to entity_ids via fuzzy match
      llm_player_search: >-
        {% set players = llm_requested_players %}
        {% set search = players | join('|') if players is list and players | length > 0 else '' %}
        {{ search }}
      llm_resolved_players: >-
        {% if llm_player_search | length > 0 %}
          {{ integration_entities('music_assistant')
             | expand
             | selectattr('name', 'in',
                 player_names_safe.split('|||')
                 | select('search', llm_player_search, ignorecase=true)
                 | list)
             | map(attribute='entity_id')
             | list }}
        {% else %}{{ [] }}{% endif %}

      # 5c — Resolve area names to area_ids via fuzzy match
      llm_area_search: >-
        {% set areas = llm_requested_areas %}
        {% set search = areas | join('|') if areas is list and areas | length > 0 else '' %}
        {{ search }}
      llm_resolved_areas: >-
        {% if llm_area_search | length > 0 %}
          {{ area_names_safe.split('|||')
             | select('search', llm_area_search, ignorecase=true)
             | map('area_id')
             | list }}
        {% else %}{{ [] }}{% endif %}

      # 5d — Did the LLM provide any usable target?
      llm_has_target: >-
        {{ llm_resolved_players | length > 0 or llm_resolved_areas | length > 0 }}

      llm_target_data:
        entity_id: "{{ llm_resolved_players }}"
        area_id: "{{ llm_resolved_areas }}"

      # 5e — Fallback: device area (only if trigger came from a physical device)
      device_area: >-
        {% if trigger.device_id | default('') | length > 0 %}
          {% set dev_area = area_name(trigger.device_id) | default('', true) %}
          {{ area_id(trigger.device_id) | default('', true)
             if dev_area in area_names_safe.split('|||')
             else '' }}
        {% else %}{{ '' }}{% endif %}

      # 5f — Fallback: default player from blueprint config
      default_player: !input default_player

      # 5g — Assemble backup target (device area > default player > empty)
      backup_target: >-
        {{ (dict(area_id=[device_area]) if device_area)
           or (dict(entity_id=[default_player]) if default_player)
           or {} }}

      # 5h — Final target: LLM target if available, else backup
      target_data: >-
        {{ (llm_target_data if llm_has_target else backup_target) | default({}, true) }}
      target: >-
        {{ dict(target_data.items() | selectattr('1')) }}

  # ── Stage 3 — Playback ────────────────────────────────────────────────

  # 6 — Gate: only attempt playback if we resolved at least one target.
  - alias: "6 · Play music only if target was resolved"
    if:
      - alias: "Check target is non-empty"
        condition: template
        value_template: "{{ target | length > 0 }}"
    then:
      # 7 — Build play_media data via choose block (explicit branches
      #     per radio_mode setting). artist/album pass empty string —
      #     Jinja `none` can coerce to "None" and confuse MA search.
      #     continue_on_error is on each play_media individually, not
      #     the outer choose, so failures are caught per-branch.
      - alias: "7 · Call play_media with radio_mode via choose"
        choose:
          # 7a — Radio mode: Never (explicit false)
          - alias: "7a · Radio mode Never"
            conditions:
              - condition: template
                value_template: "{{ play_continuously == 'Never' }}"
            sequence:
              - alias: "7a · play_media with radio_mode false"
                continue_on_error: true
                action: music_assistant.play_media
                data:
                  media_id: "{{ llm_action_data_media_id }}"
                  media_type: "{{ llm_action_data_media_type }}"
                  artist: "{{ llm_action_data_artist }}"
                  album: "{{ llm_action_data_album }}"
                  enqueue: "{{ enqueue_mode }}"
                  radio_mode: false
                target: "{{ target }}"

          # 7b — Radio mode: Always (true, unless media_type is already radio)
          - alias: "7b · Radio mode Always"
            conditions:
              - condition: template
                value_template: "{{ play_continuously == 'Always' }}"
            sequence:
              - alias: "7b · play_media with radio_mode true (unless radio type)"
                continue_on_error: true
                action: music_assistant.play_media
                data:
                  media_id: "{{ llm_action_data_media_id }}"
                  media_type: "{{ llm_action_data_media_type }}"
                  artist: "{{ llm_action_data_artist }}"
                  album: "{{ llm_action_data_album }}"
                  enqueue: "{{ enqueue_mode }}"
                  radio_mode: "{{ llm_action_data_media_type != 'radio' }}"
                target: "{{ target }}"

        # 7c — Default: Use player settings (omit radio_mode entirely)
        default:
          - alias: "7c · play_media without radio_mode (use player setting)"
            continue_on_error: true
            action: music_assistant.play_media
            data:
              media_id: "{{ llm_action_data_media_id }}"
              media_type: "{{ llm_action_data_media_type }}"
              artist: "{{ llm_action_data_artist }}"
              album: "{{ llm_action_data_album }}"
              enqueue: "{{ enqueue_mode }}"
            target: "{{ target }}"

      # 8 — Shuffle is a separate call because play_media has no shuffle param.
      - alias: "8 · Set shuffle mode — separate call because play_media has no shuffle param"
        action: media_player.shuffle_set
        data:
          shuffle: "{{ shuffle }}"
        target: "{{ target }}"
        continue_on_error: true

      # Best-effort playback verification — without this, continue_on_error
      # on play_media would produce false "Now playing…" success messages
      # when MA is down or media wasn't found.
      - alias: "8a · Brief delay for MA playback startup"
        delay:
          seconds: !input playback_verify_delay

      - alias: "8b · Check if playback actually started"
        variables:
          check_entities: >-
            {% set ns = namespace(entities=[]) %}
            {% for eid in target.get('entity_id', []) %}
              {% set ns.entities = ns.entities + [eid] %}
            {% endfor %}
            {% for aid in target.get('area_id', []) %}
              {% set ns.entities = ns.entities + (area_entities(aid)
                 | select('match', 'media_player\\.')
                 | list) %}
            {% endfor %}
            {{ ns.entities }}
          play_succeeded: >-
            {{ check_entities | length == 0
               or expand(check_entities)
                  | selectattr('state', 'in', ['playing', 'buffering'])
                  | list | length > 0 }}

  # ── Stage 4 — Build and return voice response ────────────────────────

  # 9 — Assemble response variables. Shuffle word logic lives here (not
  #     in response input defaults) so translators don't need Jinja.
  - alias: "9 · Build response variables"
    variables:
      combine: !input combine_text
      action_word: "{{ 'shuffling' if shuffle else 'playing' }}"
      resp_no_target: !input no_target_response
      resp_area: !input area_response
      resp_player: !input player_response
      resp_area_player: !input area_and_player_response
      area_list: >-
        {{ target.get('area_id', []) | map('area_name') | reject('none') | list }}
      area_info: >-
        {% if area_list | count == 0 %}
        {% elif area_list | count > 2 %}
          {{ area_list[:-1] | join(', ') ~ ' ' ~ combine ~ ' ' ~ area_list[-1] }}
        {% else %}
          {{ area_list | join(' ' ~ combine ~ ' ') }}
        {% endif %}
      player_list: >-
        {{ target.get('entity_id', [])
           | map('state_attr', 'friendly_name')
           | reject('none')
           | list }}
      player_info: >-
        {% if player_list | count == 0 %}
        {% elif player_list | count > 2 %}
          {{ player_list[:-1] | join(', ') ~ ' ' ~ combine ~ ' ' ~ player_list[-1] }}
        {% else %}
          {{ player_list | join(' ' ~ combine ~ ' ') }}
        {% endif %}
      media_info: >-
        {{ llm_result.get('media_description', '')
           | default(llm_action_data_media_id, true) }}

  # 10 — Return the final voice response. Error branch is first so a
  #      failed play_media doesn't produce a false success message.
  - alias: "10 · Set conversation response via choose"
    choose:
      - alias: "10pre · Response: playback failed (best-effort check)"
        conditions:
          - condition: template
            value_template: >-
              {{ play_succeeded is defined and not play_succeeded }}
        sequence:
          - alias: "10pre · Return play-failed response"
            set_conversation_response: >-
              Sorry, I couldn't start playback. The player may be
              unavailable or the media wasn't found. Please try again.

      - alias: "10a · Response: area + player targets"
        conditions:
          - condition: template
            value_template: >-
              {{ target.get('area_id', []) | length > 0
                 and target.get('entity_id', []) | length > 0 }}
        sequence:
          - alias: "10a · Return area-and-player response"
            set_conversation_response: >-
              {{ resp_area_player
                 | replace('<action_word>', action_word)
                 | replace('<media_info>', media_info)
                 | replace('<area_info>', area_info)
                 | replace('<player_info>', player_info) }}

      - alias: "10b · Response: area targets only"
        conditions:
          - condition: template
            value_template: >-
              {{ target.get('area_id', []) | length > 0 }}
        sequence:
          - alias: "10b · Return area response"
            set_conversation_response: >-
              {{ resp_area
                 | replace('<action_word>', action_word)
                 | replace('<media_info>', media_info)
                 | replace('<area_info>', area_info)
                 | replace('<player_info>', player_info) }}

      - alias: "10c · Response: player targets only"
        conditions:
          - condition: template
            value_template: >-
              {{ target.get('entity_id', []) | length > 0 }}
        sequence:
          - alias: "10c · Return player response"
            set_conversation_response: >-
              {{ resp_player
                 | replace('<action_word>', action_word)
                 | replace('<media_info>', media_info)
                 | replace('<area_info>', area_info)
                 | replace('<player_info>', player_info) }}

    default:
      - alias: "10d · Response: no target resolved"
        set_conversation_response: "{{ resp_no_target }}"

# Parallel mode — each voice command is self-contained with no shared
# state between runs. max:10 caps concurrent LLM queries.
mode: parallel
max: 10
max_exceeded: silent

trace:
  stored_traces: 15
