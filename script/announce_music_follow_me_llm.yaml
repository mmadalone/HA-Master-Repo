blueprint:
  name: Announce Music Follow Me (TTS, LLM)
  author: madalone
  description: >
    ![Image](https://raw.githubusercontent.com/mmadalone/HA-Master-Repo/main/images/header/announce_music_follow_me_llm-header.jpeg)

    # Announce Music Follow Me (TTS, LLM)

    Script blueprint that announces via TTS where the music was moved for a
    "music follow me" automation. Supports static messages, random message
    pools, and LLM-generated context-aware announcements with optional
    ElevenLabs voice customization.

    ### Recent changes

    - **v6 (2026-02-24):** Audit pass — trimmed whitespace in LLM prompt
      Jinja (switched to {%- -%} tags), removed redundant | string filters
      from ElevenLabs conditions, clarified tts_entity silent-exit design
      in description, added LLM timeout caveat to use_llm_fun_messages
      description

    - **v5 (2026-02-24):** Fixed Jinja whitespace contamination in
      ctx_player, time_of_day, and all tts_message branches — switched to
      whitespace-controlled tags ({%- -%}) so entity IDs and template
      outputs render without leading/trailing spaces; LLM path now
      correctly receives playback context

    - **v4 (2026-02-24):** Waterfall ctx_player resolution — prefers source
      then target based on who has active media_title; radio detection now
      uses media_content_type (channel/radio/tvshow) with string-match
      fallback only when content_type is empty; removed invalid top-level
      icon key

    - **v3 (2026-02-18):** Bumped min_version to 2024.10.0; added default to tts_entity
      and collapsed properties on all sections; fixed time_of_day whitespace;
      added continue_on_error to TTS speak actions

    - **v2 (2026-02-15):** Fixed voice_profile crash on non-ElevenLabs engines; migrated
      to action: syntax; added collapsible sections, aliases, and descriptions

    - **v1 (2026-02-14):** Initial version

  domain: script
  source_url: https://github.com/mmadalone/HA-Master-Repo/blob/main/script/announce_music_follow_me_llm.yaml
  homeassistant:
    min_version: "2024.10.0"

  input:
    tts_voice_settings:
      name: "① TTS & Voice"
      icon: mdi:account-voice
      description: TTS engine and optional ElevenLabs voice settings.
      collapsed: false
      input:
        tts_entity:
          name: TTS entity
          description: >
            The text-to-speech engine to use for announcements.
            Select your ElevenLabs TTS entity if using voice/profile options,
            or any other TTS entity for basic announcements. If left empty the
            script exits silently — useful when the calling automation handles
            TTS independently.
          default: ""
          selector:
            entity:
              domain: tts

        elevenlabs_voice:
          name: ElevenLabs voice
          description: >
            ElevenLabs voice name (e.g., "Rachel"). Leave empty if not using
            ElevenLabs or if using a voice profile instead. Ignored when a
            voice profile is set.
          default: ""
          selector:
            text: {}

        elevenlabs_voice_profile:
          name: ElevenLabs voice profile
          description: >
            ElevenLabs voice profile ID for custom cloned voices. Takes
            priority over the voice name setting. Leave empty if not using
            a custom ElevenLabs profile.
          default: ""
          selector:
            text: {}

    message_strategy:
      name: "② Message Strategy"
      icon: mdi:message-text
      collapsed: true
      description: >
        Choose between static, random, or LLM-generated announcement messages.
      input:
        use_random_messages:
          name: Use random fun messages
          description: >
            When enabled, picks a random message from the message pool instead
            of always using the default message.
          default: true
          selector:
            boolean: {}

        use_llm_fun_messages:
          name: Use LLM for fun messages
          description: >
            When enabled (and random messages is also on), uses a conversation
            agent to generate context-aware announcements instead of picking
            from the static pool. Falls back to the default message if the
            LLM call fails. Note: if the LLM hangs, the script blocks until
            HA's default timeout — there is no per-action timeout override.
          default: false
          selector:
            boolean: {}

        custom_random_messages:
          name: Random messages
          description: >
            Pool of announcement templates for random mode. Use {player_name}
            as a placeholder for the target speaker's friendly name.
          default:
            - "Moving the music to {player_name}."
            - "Music transferred to {player_name}."
            - "Playback moved to {player_name}."
          selector:
            object: {}

        default_message:
          name: Default message
          description: >
            Fallback message template used when random mode is off or when the
            LLM fails. Use {player_name} as a placeholder.
          default: "Moving the music to {player_name}."
          selector:
            text:
              multiline: true

    llm_settings:
      name: "③ LLM Configuration"
      icon: mdi:robot
      collapsed: true
      description: >
        Settings for LLM-generated announcements. Only used when both random
        messages and LLM fun messages are enabled.
      input:
        use_playback_context:
          name: Include playback context in LLM prompt
          description: >
            When enabled, tells the LLM what's currently playing (track name,
            artist, or radio station) so it can make context-aware comments.
          default: true
          selector:
            boolean: {}

        llm_prompt_template:
          name: LLM prompt template
          description: >
            System prompt sent to the conversation agent. Use {player_name},
            {current_time}, and {time_of_day} as placeholders. Keep it short
            — the LLM should produce a single sentence.
          default: >
            You are a casual smart home assistant.
            Say the music moved to "{player_name}" and briefly comment on it.
            Time: {current_time}, {time_of_day}.
          selector:
            text:
              multiline: true

        llm_agent_id:
          name: Conversation agent
          description: >
            The conversation agent (LLM) to generate fun announcements. Can be
            Extended OpenAI Conversation, OpenAI Conversation, or any agent
            that supports conversation.process.
          default: ""
          selector:
            conversation_agent: {}

mode: queued
max_exceeded: silent

fields:
  target_player:
    name: Target player
    description: The media player where music is being moved to.
    required: true
    selector:
      entity:
        domain: media_player

  source_player:
    name: Source player
    description: >
      The media player where music was playing before the move.
      Used to read current track info for LLM context. Falls back
      to target_player if not provided.
    required: false
    selector:
      entity:
        domain: media_player

  tts_output_player:
    name: TTS output player (optional)
    description: >
      Override where the TTS announcement plays. If not provided,
      the announcement plays on the target player.
    required: false
    selector:
      entity:
        domain: media_player

variables:
  tts_entity_id: !input tts_entity
  random_mode: !input use_random_messages
  use_llm: !input use_llm_fun_messages
  use_context: !input use_playback_context
  llm_agent: !input llm_agent_id
  prompt_tpl: !input llm_prompt_template
  default_msg_tpl: !input default_message
  custom_msgs: !input custom_random_messages
  el_voice: !input elevenlabs_voice
  el_voice_profile: !input elevenlabs_voice_profile

sequence:
  - alias: "Resolve player names, playback context, and time of day"
    variables:
      player_name: "{{ state_attr(target_player, 'friendly_name') | default(target_player) }}"
      ctx_player: >-
        {%- set src = source_player if source_player is defined and source_player else '' -%}
        {%- if src and state_attr(src, 'media_title') -%}
          {{ src }}
        {%- elif state_attr(target_player, 'media_title') -%}
          {{ target_player }}
        {%- elif src -%}
          {{ src }}
        {%- else -%}
          {{ target_player }}
        {%- endif -%}
      media_title: "{{ state_attr(ctx_player, 'media_title') | default('', true) }}"
      media_artist: "{{ state_attr(ctx_player, 'media_artist') | default('', true) }}"
      media_content_type: "{{ state_attr(ctx_player, 'media_content_type') | default('', true) | lower }}"
      current_time: "{{ now().strftime('%H:%M') }}"
      time_of_day: >-
        {%- set h = now().hour -%}
        {{ 'late night' if h < 6
           else 'morning' if h < 12
           else 'afternoon' if h < 18
           else 'evening' }}

  - alias: "Decide announcement message — LLM, random pool, or default"
    choose:
      - alias: "LLM path — generate context-aware message via conversation agent"
        conditions:
          - condition: template
            value_template: "{{ random_mode and use_llm }}"
        sequence:
          - alias: "Call conversation agent for a fun announcement (non-critical)"
            action: conversation.process
            data:
              agent_id: "{{ llm_agent or omit }}"
              text: >-
                {{
                  prompt_tpl
                  | replace('{player_name}', player_name)
                  | replace('{current_time}', current_time)
                  | replace('{time_of_day}', time_of_day)
                }}
                {%- if use_context and media_title %}
                {%- set is_radio = media_content_type in ['channel', 'radio', 'tvshow']
                   or (media_content_type == '' and ('radio' in media_title | lower or 'radio' in media_artist | lower)) %}
                {%- if is_radio %}
                currently tuned to the radio station "{{ media_title }}"{% if media_artist %} ({{ media_artist }}){% endif %}. this is a live radio stream, not a song or track.
                {%- else %}
                currently playing the track "{{ media_title }}"{% if media_artist %} by {{ media_artist }}{% endif %}.
                {%- endif %}
                {%- endif %}
            response_variable: llm_response
            continue_on_error: true

          - alias: "Extract LLM response text — fall back to default on failure"
            variables:
              tts_message: >-
                {%- set r = llm_response | default({}) -%}
                {%- set resp = r.response | default({}) -%}
                {%- if resp.speech is defined
                      and resp.speech.plain is defined
                      and resp.speech.plain.speech is defined -%}
                  {{ resp.speech.plain.speech | trim }}
                {%- elif resp.text is defined -%}
                  {{ resp.text | trim }}
                {%- else -%}
                  {{ default_msg_tpl | replace('{player_name}', player_name) }}
                {%- endif -%}

      - alias: "Static random path — pick from message pool"
        conditions:
          - condition: template
            value_template: "{{ random_mode and not use_llm }}"
        sequence:
          - alias: "Pick a random message and substitute player name"
            variables:
              tts_message: >-
                {%- if custom_msgs -%}
                  {{ custom_msgs | random
                     | replace('{player_name}', player_name) }}
                {%- else -%}
                  {{ default_msg_tpl | replace('{player_name}', player_name) }}
                {%- endif -%}

    default:
      - alias: "Default path — use the static default message"
        variables:
          tts_message: >-
            {{ default_msg_tpl | replace('{player_name}', player_name) }}

  - alias: "Resolve TTS output target — override or target player"
    variables:
      tts_target_player: >-
        {{ tts_output_player if tts_output_player is defined and tts_output_player else target_player }}

  - alias: "Speak announcement — branch on ElevenLabs options"
    choose:
      - alias: "TTS with voice_profile (ElevenLabs custom profile)"
        conditions:
          - condition: template
            value_template: "{{ el_voice_profile | default('') | length > 0 }}"
        sequence:
          - alias: "Speak via ElevenLabs with voice profile"
            action: tts.speak
            target:
              entity_id: "{{ tts_entity_id }}"
            data:
              media_player_entity_id: "{{ tts_target_player }}"
              message: "{{ tts_message }}"
              options:
                voice_profile: "{{ el_voice_profile }}"
            continue_on_error: true

      - alias: "TTS with voice name only (ElevenLabs voice, no profile)"
        conditions:
          - condition: template
            value_template: "{{ el_voice | default('') | length > 0 }}"
        sequence:
          - alias: "Speak via ElevenLabs with voice name"
            action: tts.speak
            target:
              entity_id: "{{ tts_entity_id }}"
            data:
              media_player_entity_id: "{{ tts_target_player }}"
              message: "{{ tts_message }}"
              options:
                voice: "{{ el_voice }}"
            continue_on_error: true

    default:
      - alias: "Speak via generic TTS — no ElevenLabs options"
        action: tts.speak
        target:
          entity_id: "{{ tts_entity_id }}"
        data:
          media_player_entity_id: "{{ tts_target_player }}"
          message: "{{ tts_message }}"
        continue_on_error: true
